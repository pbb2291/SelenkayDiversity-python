{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bacbd0-7acf-402a-9495-429533a5c681",
   "metadata": {},
   "source": [
    "### Outputting Grid Metrics as 2D and 3D Arrays\n",
    "*PB 10/18/22*\n",
    "\n",
    "Based on OutputTifsandNetCDFs_3.ipy in Structural Complexity Mpala Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f863cdb2-5ec4-40c5-9fc1-f08c9a6fbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/n/home02/pbb/scripts/halo-metadata-server/Selenkay/bin/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from Functions import fill2Darray, classifyVeg_GGW, classifyVeg_GGST\n",
    "\n",
    "### TBD: THIS HASN\"T YET BEEN ADAPTED FOR THE MANGO RUN!\n",
    "# Needs to be made to work in a loop and with the new metrics (cover and percentiles of the grass layer)\n",
    "# 2/9/23\n",
    "# only works for the initial run, not for \"mango\" yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d7a9cd-00ab-4f7d-bcad-38a01a921b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This currently works! \n",
    "# It is only running for outputs from a single shapefile though,\n",
    "# In future versions, you may want to put it all in a loop \n",
    "# and change up the output folder structure (/Raster/30mRadius/Spot7B/2D/)\n",
    "# Also, there is a noticable offset between the rasters and the shapefile\n",
    "# the rasters appear shifted ~xysize/2 meters to the left and north\n",
    "# PB 10/18/2022\n",
    "\n",
    "# # # USER INPUTS: \n",
    "\n",
    "# Set a Label for this run (unique label id)\n",
    "# label= 'initial'\n",
    "# mango run - 2/8/23\n",
    "label = 'mango'\n",
    "\n",
    "# Radii to loop over\n",
    "# radii = [20, 30, 50, 80, 130]\n",
    "\n",
    "# Radius of shapefile to use\n",
    "radius = 130\n",
    "\n",
    "# Set the pickle metrics to draw from\n",
    "metricdir = Path(f'/n/davies_lab/Users/pbb/SelenkayDiversity/data/out/Metrics/{label}/{radius}mRadius/')\n",
    "\n",
    "# Horizontal Grid size\n",
    "xysize = 0.5\n",
    "\n",
    "# Ground threshold\n",
    "groundthreshold = 0.05\n",
    "\n",
    "# Set CRS\n",
    "# Selenkay is 32737 (WGS84 UTM37S)\n",
    "epsg='32737'\n",
    "\n",
    "# Shapefile of Plots (for iterively setting boundaries of the grid)\n",
    "# NOTE: This is the dissolved file without a buffer\n",
    "# each feature is a plot polygon, marked by Site and Block number\n",
    "shpf = Path(f'/n/home02/pbb/scripts/halo-metadata-server/Selenkay/data/in/BoundaryShapefiles/SelenkaySpotPolygons_IncreasingRadius/SelenkaySpotPolygons_{radius}mRadius.shp')\n",
    "shpdf = gpd.read_file(shpf)\n",
    "\n",
    "featureIDcol = 'Spot'\n",
    "\n",
    "# Output Data:\n",
    "\n",
    "# Outdirectory for rasters and netcdfs\n",
    "outdir_rast = Path(f'/n/davies_lab/Users/pbb/SelenkayDiversity/data/out/Rasters/{label}/{radius}mRadius/')\n",
    "\n",
    "if not outdir_rast.exists():\n",
    "    outdir_rast.mkdir()\n",
    "\n",
    "# list of 3D metrics to output,\n",
    "# corresponding to the names in the saved cover dictionaries\n",
    "# Note: all percentile metrics get output by default\n",
    "metriclabels3d = ['Npulses', 'CoverD1', 'CoverD2', 'CoverD1byH', 'CoverD2byH', 'FHPD1', 'FHPD2']\n",
    "\n",
    "# # #  END USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59473579-c81c-4e43-b60d-7f96dd993ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spot 1E...\n",
      "\tFinished 2D outputs for Spot 1E. 18.648810386657715 seconds.\n",
      "\tFinished 3D outputs for Spot 1E. 110.09253811836243 seconds.\n",
      "\n",
      "Starting Spot 1D...\n",
      "\tFinished 2D outputs for Spot 1D. 21.722548246383667 seconds.\n",
      "\tFinished 3D outputs for Spot 1D. 157.1882827281952 seconds.\n",
      "\n",
      "Starting Spot 1A...\n",
      "\tFinished 2D outputs for Spot 1A. 30.130663871765137 seconds.\n",
      "\tFinished 3D outputs for Spot 1A. 189.56265115737915 seconds.\n",
      "\n",
      "Starting Spot 1B...\n",
      "\tFinished 2D outputs for Spot 1B. 23.470935344696045 seconds.\n",
      "\tFinished 3D outputs for Spot 1B. 166.58925366401672 seconds.\n",
      "\n",
      "Starting Spot 1C...\n",
      "\tFinished 2D outputs for Spot 1C. 26.640344619750977 seconds.\n",
      "\tFinished 3D outputs for Spot 1C. 497.37966418266296 seconds.\n",
      "\n",
      "Starting Spot 2C...\n",
      "\tFinished 2D outputs for Spot 2C. 26.819496870040894 seconds.\n",
      "\tFinished 3D outputs for Spot 2C. 243.03565788269043 seconds.\n",
      "\n",
      "Starting Spot 2A...\n",
      "\tFinished 2D outputs for Spot 2A. 27.49851083755493 seconds.\n"
     ]
    }
   ],
   "source": [
    "# For Testing- use only 7 and 8 here\n",
    "# Sites = [s for s in shpdf[featureIDcol] if (('7' in s)|('8' in s))]\n",
    "# Testing - Only use 3a\n",
    "# shpdf = shpdf.query(\"Spot == '3a'\").copy(deep=True)\n",
    "\n",
    "# Sites to loop through\n",
    "Sites = [s for s in shpdf[featureIDcol]]\n",
    "\n",
    "# For each site\n",
    "for s in Sites:\n",
    "    \n",
    "    print(f'Starting {featureIDcol} {s}...')\n",
    "          \n",
    "    start = time.time()\n",
    "    \n",
    "    # Get organized:\n",
    "            \n",
    "    # Make output dir if not already made\n",
    "    # Note: removed the \"2D\" and \"3D\" product folder structure on 102722\n",
    "    # Since it could get confusing with the Spot names\n",
    "    if not Path(f'{outdir_rast}/{s}/').exists():\n",
    "        Path(f'{outdir_rast}/{s}/').mkdir()\n",
    "        \n",
    "    # # Make 3D outdir if not already made\n",
    "    # if not Path(f'{outdir_rast}/{s}/3D').exists():\n",
    "    #     Path(f'{outdir_rast}/{s}/3D').mkdir()\n",
    "\n",
    "    # 1) Load Inputs, and Redefine Grid\n",
    "\n",
    "    # Load percentile height metric dict\n",
    "    with open(f'{metricdir}/{s}_{xysize}mgrid_percmetrics.obj', 'rb') as of:\n",
    "        perc = pickle.load(of)\n",
    "\n",
    "    # Load Cover percentile dict\n",
    "    with open(f'{metricdir}/{s}_{xysize}mgrid_covermetrics.obj', 'rb') as of:\n",
    "        cover = pickle.load(of)\n",
    "        \n",
    "    # Load Complexity dict\n",
    "    with open(f'{metricdir}/{s}_{xysize}mgrid_complexitymetrics.obj', 'rb') as of                                                                                                                                                                                                                                                                                                                                    :\n",
    "        complexity = pickle.load(of)\n",
    "\n",
    "    # Match site to get the plot polygon\n",
    "    feat_gs = shpdf.loc[shpdf[featureIDcol]==s]\n",
    "\n",
    "    # Set bounds of grid to fill\n",
    "    xmin=float(feat_gs.geometry.bounds.minx)\n",
    "    ymin=float(feat_gs.geometry.bounds.miny)\n",
    "    xmax=float(feat_gs.geometry.bounds.maxx)\n",
    "    ymax=float(feat_gs.geometry.bounds.maxy)\n",
    "\n",
    "    # Make the coordinates of the grid\n",
    "    x_grid = np.arange(xmin, xmax, step=xysize)\n",
    "    y_grid = np.arange(ymin, ymax, step=xysize)\n",
    "\n",
    "    # Mesh the grid into 2 matrices of x and y coordinates\n",
    "    x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    # Find the index of where all the data values belong in the grid\n",
    "    xlist = [k[0] for k in cover.keys()]\n",
    "    ylist = [k[1] for k in cover.keys()]\n",
    "\n",
    "    xidx = []\n",
    "    yidx = []\n",
    "\n",
    "    # for each unique x,y location in the list of data values\n",
    "    for x, y in zip(xlist, ylist):\n",
    "\n",
    "        # Find it's unique x and y index location on the grid (ex: [0,1], [100,3], ...)        \n",
    "        # xi = np.flatnonzero(x_grid==x)\n",
    "        # yi = np.flatnonzero(y_grid==y)\n",
    "        \n",
    "        # Note: implemented the below, because I think there's a rounding error issue\n",
    "        # grid x_grid and xlist don't quite match, off by about 0.009 m\n",
    "        # 10/18/22\n",
    "        \n",
    "        # Find the closest value on the grid to make the index\n",
    "        # calculate the difference array\n",
    "        xdiff = np.absolute(x-x_grid)\n",
    "        # find the index of minimum element from the array\n",
    "        xindex = xdiff.argmin()\n",
    "        \n",
    "        # calculate the difference array\n",
    "        ydiff = np.absolute(y-y_grid)\n",
    "        # find the index of minimum element from the array\n",
    "        yindex = ydiff.argmin()\n",
    "        \n",
    "        xi = np.flatnonzero(x_grid==x_grid[xindex])\n",
    "        yi = np.flatnonzero(y_grid==y_grid[yindex])\n",
    "\n",
    "        # If there is a location (not empty)\n",
    "        if ((xi.size > 0) & (yi.size > 0)):\n",
    "\n",
    "            # Add to the list\n",
    "            xidx.append(xi[0])\n",
    "            yidx.append(yi[0])\n",
    "\n",
    "        else: \n",
    "\n",
    "            # Otherwise, mark them both with nans\n",
    "            xidx.append(np.nan)\n",
    "            yidx.append(np.nan)\n",
    "    \n",
    "    # Make an index for filtering arrays \n",
    "    # filterindex = np.array(xidx) >= 0\n",
    "    \n",
    "    # 2) Load, Reshape, and Output 2D Metrics\n",
    "\n",
    "    # Get all the data dicts from the nested perc dictionary\n",
    "    v = list(perc.values())\n",
    "\n",
    "    # unpack all vars into lists\n",
    "    perc0 = [i[0][0] for i in v]\n",
    "    perc25 = [i[25][0] for i in v]\n",
    "    perc50 = [i[50][0] for i in v]\n",
    "    perc75 = [i[75][0] for i in v]\n",
    "    perc98 = [i[98][0] for i in v]\n",
    "    perc100 = [i[100][0] for i in v]\n",
    "    meanh = [i['mean'][0] for i in v]\n",
    "    stdh = [i['std'][0] for i in v]\n",
    "    \n",
    "    # Classify Vegetation using 98th percentile height\n",
    "    vegtypeGGST = [classifyVeg_GGST(p, groundthreshold=groundthreshold) for p in perc98]\n",
    "    vegtypeGGW = [classifyVeg_GGW(p, groundthreshold=groundthreshold) for p in perc98]\n",
    "    \n",
    "    # Get all the data vals from the nested complexity dictionary\n",
    "    vc = list(complexity.values())\n",
    "\n",
    "    # unpack all vars into lists\n",
    "    nlayers = [i['nlayers'] for i in vc]\n",
    "    maxpeakh = [i['maxpeakh'] for i in vc]\n",
    "    gapsize = [i['gapsize'] for i in vc]\n",
    "    ptoh = [i['ptoh'] for i in vc]\n",
    "    cscore = [i['cscore'] for i in vc]\n",
    "    FHD = [i['FHD'] for i in vc]\n",
    "    VDR = [i['VDR'] for i in vc]\n",
    "    meanpeakh = [i['meanpeakh'] for i in vc]\n",
    "    stdpeakh = [i['stdpeakh'] for i in vc]\n",
    "    cvpeakh = [i['cvpeakh'] for i in vc]\n",
    "    VDRpeak = [i['VDRpeak'] for i in vc]\n",
    "    herbh = [i['herbh'] for i in vc]\n",
    "\n",
    "    # 'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh'\n",
    "    # nlayers, gapsize, maxpeakh, ptoh, cscore, FHD, VDR, meanpeakh, stdpeakh, cvpeakh\n",
    "\n",
    "    # Reshape vars into 2D arrays and store in a dictionary\n",
    "    outdict = {}.fromkeys(['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "                           'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh'])\n",
    "\n",
    "    for m, l in zip([perc0, perc25, perc50, perc75, perc98, perc100, meanh, stdh, vegtypeGGST, vegtypeGGW,\n",
    "                     nlayers, gapsize,maxpeakh, ptoh, cscore, FHD, VDR, meanpeakh, stdpeakh, cvpeakh, VDRpeak, herbh],\n",
    "                    ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "                     'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh']):\n",
    "\n",
    "        outdict[l] = fill2Darray(data=m, shape=x_mesh.shape,\n",
    "                                 xindices=xidx, yindices=yidx, plot=False)\n",
    "\n",
    "    # Output 2D Arrays as geotifs\n",
    "    for l in ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std', 'vegtypeGGST', 'vegtypeGGW',\n",
    "              'nlayers', 'gapsize', 'maxpeakh','ptoh', 'cscore', 'FHD', 'VDR', 'meanpeakh', 'stdpeakh', 'cvpeakh', 'VDRpeak', 'herbh']:\n",
    "\n",
    "        # Grab one metric for output\n",
    "        m = outdict[l]\n",
    "\n",
    "        # Mirror Image the metric\n",
    "        # Note: You do this because rioxarray wants data\n",
    "        # ordered with positive x (left to right)\n",
    "        # but with negative y (top to bottom)\n",
    "        # This really just makes the export to geotif go smoothly,\n",
    "        # with a correct affine transform \n",
    "        m = np.flipud(m)\n",
    "\n",
    "        # Also flip y coordinates, so that they're correctly read into x array\n",
    "        # y_grid_flip = np.flip(y_grid)\n",
    "        # NOTE: adding xysize to y coord so that it marks Top left corner\n",
    "        # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "        y_grid_flip = np.flip(y_grid) + xysize\n",
    "\n",
    "        # put in an xarray\n",
    "        # 2D\n",
    "        m_xr = xr.DataArray(data=m,\n",
    "                            coords={\"y\": y_grid_flip,\n",
    "                                    \"x\": x_grid},\n",
    "                            dims=[\"y\", \"x\"])\n",
    "\n",
    "        # Write CRS and Nodata value and dims to xarray\n",
    "        m_xr.rio.write_crs(f\"epsg:{epsg}\",\n",
    "                           inplace=True)\n",
    "        m_xr.rio.write_nodata(-9999,\n",
    "                              inplace=True)\n",
    "        m_xr.rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                  y_dim=\"y\",\n",
    "                                  inplace=True)\n",
    "        m_xr.rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "        # make an output Label\n",
    "        label = l.replace(' ', '').replace('.', 'p').replace('[m]', '')\n",
    "\n",
    "        m_xr.rio.to_raster(f'{outdir_rast}/{s}/{s}_{label}.tif')\n",
    "\n",
    "        # print(f'{l} done')\n",
    "\n",
    "    end2d = time.time()\n",
    "\n",
    "    print(f'\\tFinished 2D outputs for {featureIDcol} {s}. {end2d-start} seconds.')\n",
    "\n",
    "    \n",
    "    # 3) Load, Reshape, and Output 3D Metrics\n",
    "\n",
    "    # Unpack cover values as a list\n",
    "    v3 = list(cover.values())\n",
    "\n",
    "    # Get list of heights for later\n",
    "    hbins = v3[0]['HeightBins']\n",
    "    \n",
    "    # Make shape for output array\n",
    "    # note - y, then x here\n",
    "    shape = (len(y_grid), len(x_grid))\n",
    "\n",
    "    # for each set of 3D metrics\n",
    "    for l3 in metriclabels3d:\n",
    "\n",
    "        # list to fill with xarrays from each height\n",
    "        xr_list = []\n",
    "\n",
    "        # Deals with an issue caused by using np.diff\n",
    "        # if there's a difference metric, then the last height does not have a value\n",
    "        if ((\"byH\" in l3) | ('FHP' in l3)) :\n",
    "            hbinz = hbins[1:]\n",
    "        else:\n",
    "            hbinz = hbins\n",
    "\n",
    "        # for each height bin\n",
    "        for hidx, h in enumerate(hbinz): \n",
    "\n",
    "            # make an array of all the values\n",
    "            m = np.array([i[l3][hidx] for i in v3])\n",
    "\n",
    "            # make an empty output array, filled with nans\n",
    "            output_array = np.full(shape, np.nan)\n",
    "\n",
    "            # if that data needs to be filtered\n",
    "#             if filterindex:\n",
    "\n",
    "#                 data = m[filterindex]\n",
    "#                 xindices = np.array(xidx)[filterindex]\n",
    "#                 yindices = np.array(yidx)[filterindex]\n",
    "\n",
    "            # Convert to int\n",
    "            xindices = np.array(xidx).astype(int)\n",
    "            yindices = np.array(yidx).astype(int)\n",
    "\n",
    "            # Fill any inf values in data with -9999\n",
    "            # data[np.isfinite(data, where=False)] = -9999\n",
    "\n",
    "            # stick into the array\n",
    "            # IMPORTANT NOTE HERE: it's y, then x, not the other way around\n",
    "            output_array[yindices, xindices] = m\n",
    "\n",
    "            # Mirror Image the metric\n",
    "            # Note: You do this because rioxarray wants data\n",
    "            # ordered with positive x (left to right)\n",
    "            # but with negative y (top to bottom)\n",
    "            # This really just makes the export to geotif go smoothly,\n",
    "            # with a correct affine transform \n",
    "            output_array = np.flipud(output_array)\n",
    "\n",
    "            # Also flip y coordinates, so that they're correctly read into x array \n",
    "            # y_grid_flip = np.flip(y_grid)\n",
    "            # NOTE: adding xysize to y coord so that it marks Top left corner\n",
    "            # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "            y_grid_flip = np.flip(y_grid) + xysize\n",
    "\n",
    "            # put in an xarray\n",
    "            # 2D\n",
    "            m_xr = xr.DataArray(data=output_array,\n",
    "                                coords={\"y\": y_grid_flip,\n",
    "                                        \"x\": x_grid},\n",
    "                                dims=[\"y\", \"x\"])\n",
    "\n",
    "            # Write CRS and Nodata value\n",
    "            m_xr.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "            m_xr.rio.write_nodata(-9999, inplace=True)\n",
    "            m_xr.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n",
    "            m_xr.rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "            # add to list \n",
    "            xr_list.append(m_xr)\n",
    "\n",
    "        # Concatenate dataarrays\n",
    "        # https://docs.xarray.dev/en/stable/user-guide/combining.html#combine\n",
    "        # setting the values of the new dimension to be height\n",
    "        ds = xr.concat(xr_list, hbinz)\n",
    "        ds = ds.rename({'concat_dim':'z'})\n",
    "\n",
    "        # Set it's name\n",
    "        ds.name = l3\n",
    "\n",
    "        # output to netcdf\n",
    "        ds.to_netcdf(f'{outdir_rast}/{s}/{s}_{l3}.nc')\n",
    "\n",
    "    end3d = time.time()\n",
    "\n",
    "    print(f'\\tFinished 3D outputs for {featureIDcol} {s}. {end3d-start} seconds.\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e548ad-e878-4531-9642-a65bdf262e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure showing slight offset between coords in xlist (from cover_dict) and coords made with np.arange\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(x_mesh, y_mesh, s=2, c='b')\n",
    "# ax.scatter(xlist, ylist, s=2, c='k')\n",
    "# ax.axis('equal')\n",
    "# ax.margins(x=-0.49, y=-0.49) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a4f9e8-2ec1-4222-9326-7ad47d6318d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array(vegtypeGGST)[np.array(vegtypeGGST)>0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Halo]",
   "language": "python",
   "name": "conda-env-.conda-Halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
