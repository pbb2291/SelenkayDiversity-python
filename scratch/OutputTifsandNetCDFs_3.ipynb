{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8271d0f5-1b88-40c6-9cce-0a37a18933ba",
   "metadata": {},
   "source": [
    "### Outputting Grid Metrics as 2D and 3D Arrays\n",
    "*PB 8/12/22* \n",
    "\n",
    "Redone with huge speed improvements made by\n",
    "incorporating vectorized indexing in numpy to fill grids\n",
    "and using xarray for geotif and netcdf exports.\n",
    "\n",
    "----\n",
    "\n",
    "##### Useful links for geotif export and affine transform\n",
    "\n",
    "https://rasterio.readthedocs.io/en/latest/topics/georeferencing.html\n",
    "\n",
    "http://dirsig.cis.rit.edu/docs/new/affine.html\n",
    "\n",
    "https://corteva.github.io/rioxarray/stable/getting_started/crs_management.html\n",
    "\n",
    "https://github.com/rasterio/affine\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8035d892-5711-4eff-8d85-7c36b614d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/n/home02/pbb/scripts/halo-metadata-server/StructuralComplexity_Tyler')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "# from geocube.api.core import make_geocube\n",
    "# from shapely.geometry import Point\n",
    "# from geocube.rasterize import rasterize_points_griddata\n",
    "# sys.path.append('/n/home02/pbb/scripts/halo-metadata-server/')\n",
    "# from Cloud_Class import Cloud, calccover\n",
    "# from StructComplexity_f import exportTIF\n",
    "# import os\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14c9827-9206-49e7-9cb6-08080a7d1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # USER INPUTS: \n",
    "\n",
    "# Input Data:\n",
    "\n",
    "# Set the pickle metrics to draw from\n",
    "metricdir = '/n/davies_lab/Users/pbb/StructuralComplexity_Tyler/data/out/UHURU_100Plots_metrics'\n",
    "\n",
    "# Horizontal Grid size\n",
    "# 25 cm voxelss\n",
    "xysize = 0.25\n",
    "\n",
    "# Set CRS\n",
    "epsg = '32637'\n",
    "\n",
    "# Shapefile of Plots (for iterively setting boundaries of the grid)\n",
    "# NOTE: This is the dissolved file without a buffer\n",
    "# each feature is a plot polygon, marked by Site and Block number\n",
    "shpf = Path('/n/home02/pbb/scripts/halo-metadata-server/StructuralComplexity_Tyler/data/in/UHURU_Polygons/UHURU_100mPlots_Dissolved.shp')\n",
    "shpdf = gpd.read_file(shpf)\n",
    "\n",
    "# Sites to loop through\n",
    "Sites = ['South', 'Central', 'North']\n",
    "# Blocks within each site\n",
    "Blocks = [1, 2, 3]\n",
    "\n",
    "# Output Data:\n",
    "\n",
    "# Outdirectory for rasters and netcdfs\n",
    "outdir_rast = '/n/davies_lab/Users/pbb/StructuralComplexity_Tyler/data/out/UHURU_100Plots_rasters/20220812'\n",
    "\n",
    "# list of 3D metrics to output,\n",
    "# corresponding to the names in the saved cover dictionaries\n",
    "# Note: all percentile metrics get output by default\n",
    "metriclabels3d = ['Npulses', 'CoverD1', 'CoverD2', 'CoverD1byH', 'CoverD2byH', 'FHPD1', 'FHPD2']\n",
    "\n",
    "# # #  END USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e812a6-3ce2-4c9f-9f4a-2302c5ab5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for filling arrays\n",
    "def fill2Darray(data, shape, xindices, yindices, filteridx=None, plot=False):\n",
    "    \n",
    "    # make an empty output array, filled with nans\n",
    "    output_array = np.full(shape, np.nan)\n",
    "    \n",
    "    # if that data needs to be filtered\n",
    "    if filteridx.size > 0:\n",
    "        \n",
    "        data = np.array(data)[filteridx]\n",
    "        xindices = np.array(xidx)[filteridx]\n",
    "        yindices = np.array(yidx)[filteridx]\n",
    "    \n",
    "    # Convert to int\n",
    "    xindices = xindices.astype(int)\n",
    "    yindices = yindices.astype(int)\n",
    "        \n",
    "    # fill the output array with data values, using the above indices\n",
    "    output_array[yindices, xindices] = data\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        a = ax.imshow(output_array, cmap='magma')\n",
    "        fig.colorbar(a)\n",
    "        \n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad7b149-9de3-43b1-bb56-509abf1b6828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU South Block 1. 68.9206395149231 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU South Block 1. 310.86160016059875 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU South Block 2. 86.43612170219421 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU South Block 2. 378.0471522808075 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU South Block 3. 91.46655941009521 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU South Block 3. 424.8815679550171 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU Central Block 1. 119.92950105667114 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU Central Block 1. 584.528507232666 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU Central Block 2. 116.0377721786499 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU Central Block 2. 607.7618050575256 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU Central Block 3. 108.94647789001465 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU Central Block 3. 431.86274456977844 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU North Block 1. 132.26367378234863 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU North Block 1. 594.9546947479248 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU North Block 2. 115.32158470153809 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU North Block 2. 551.6125280857086 seconds. \n",
      "\n",
      "0th done\n",
      "25th done\n",
      "50th done\n",
      "75th done\n",
      "98th done\n",
      "100th done\n",
      "Mean done\n",
      "Std done\n",
      "Finished 2D outputs for UHURU North Block 3. 93.02355289459229 seconds. \n",
      "\n",
      "Finished 3D outputs for UHURU North Block 3. 447.3920636177063 seconds. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each site\n",
    "for s in Sites:\n",
    "    \n",
    "    # for each block (3 per site)\n",
    "    for b in Blocks:\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "    # 1) Load Inputs, and Redefine Grid\n",
    "    \n",
    "        # Load percentile height metric dict\n",
    "        with open(f'{metricdir}/UHURU{s}_{s}_{b}_{xysize}mgrid_percmetrics.obj', 'rb') as of:\n",
    "            perc = pickle.load(of)\n",
    "            \n",
    "        # Load Cover percentile dict\n",
    "        with open(f'{metricdir}/UHURU{s}_{s}_{b}_{xysize}mgrid_covermetrics.obj', 'rb') as of:\n",
    "            cover = pickle.load(of)\n",
    "\n",
    "        # Match site and block to get the plot polygon\n",
    "        feat_gs = shpdf.loc[((shpdf.Site==s) & (shpdf.Block==b))]\n",
    "\n",
    "        # Set bounds of grid to fill\n",
    "        xmin=float(feat_gs.geometry.bounds.minx)\n",
    "        ymin=float(feat_gs.geometry.bounds.miny)\n",
    "        xmax=float(feat_gs.geometry.bounds.maxx)\n",
    "        ymax=float(feat_gs.geometry.bounds.maxy)\n",
    "\n",
    "        # Make the coordinates of the grid\n",
    "        x_grid = np.arange(xmin, xmax, step=xysize)\n",
    "        y_grid = np.arange(ymin, ymax, step=xysize)\n",
    "\n",
    "        # Mesh the grid into 2 matrices of x and y coordinates\n",
    "        x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "        # Find the index of where all the data values belong in the grid\n",
    "        xlist = [k[0] for k in cover.keys()]\n",
    "        ylist = [k[1] for k in cover.keys()]\n",
    "\n",
    "        xidx = []\n",
    "        yidx = []\n",
    "\n",
    "        # for each unique x,y location in the list of data values\n",
    "        for x, y in zip(xlist, ylist):\n",
    "\n",
    "            # Find it's unique x and y index location on the grid (ex: [0,1], [100,3], ...)\n",
    "            xi = np.flatnonzero(x_grid==x)\n",
    "            yi = np.flatnonzero(y_grid==y)\n",
    "\n",
    "            # If there is a location (not empty)\n",
    "            if ((xi.size > 0) & (yi.size > 0)):\n",
    "\n",
    "                # Add to the list, as an integer\n",
    "                xidx.append(xi[0])\n",
    "                yidx.append(yi[0])\n",
    "\n",
    "            else: \n",
    "\n",
    "                # Otherwise, mark them both with nans\n",
    "                xidx.append(np.nan)\n",
    "                yidx.append(np.nan)\n",
    "\n",
    "\n",
    "        # Make an index for filtering arrays \n",
    "        filterindex = np.array(xidx) >= 0 \n",
    "\n",
    "\n",
    "    # 2) Load, Reshape, and Output 2D Metrics\n",
    "\n",
    "        # Get all the data dicts from the nested perc dictionary\n",
    "        v = list(perc.values())\n",
    "\n",
    "        # unpack all vars into lists\n",
    "        perc0 = [i[0][0] for i in v]\n",
    "        perc25 = [i[25][0] for i in v]\n",
    "        perc50 = [i[50][0] for i in v]\n",
    "        perc75 = [i[75][0] for i in v]\n",
    "        perc98 = [i[98][0] for i in v]\n",
    "        perc100 = [i[100][0] for i in v]\n",
    "        meanh = [i['mean'][0] for i in v]\n",
    "        stdh = [i['std'][0] for i in v]\n",
    "        \n",
    "        # Reshape vars into 2D arrays and store in a dictionary\n",
    "        outdict = {}.fromkeys(['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std'])\n",
    "\n",
    "        for m, l in zip([perc0, perc25, perc50, perc75, perc98, perc100, meanh, stdh],\n",
    "                        ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std']):\n",
    "\n",
    "            outdict[l] = fill2Darray(data=m, shape=x_mesh.shape,\n",
    "                                     xindices=xidx, yindices=yidx,\n",
    "                                     filteridx=filterindex, plot=False)\n",
    "\n",
    "        # Output 2D Arrays as geotifs\n",
    "        for l in ['0th','25th', '50th', '75th', '98th', '100th', 'Mean', 'Std']:\n",
    "\n",
    "            # Grab one metric for output\n",
    "            m = outdict[l]\n",
    "            \n",
    "            # Mirror Image the metric\n",
    "            # Note: You do this because rioxarray wants data\n",
    "            # ordered with positive x (left to right)\n",
    "            # but with negative y (top to bottom)\n",
    "            # This really just makes the export to geotif go smoothly,\n",
    "            # with a correct affine transform \n",
    "            m = np.flipud(m)\n",
    "            \n",
    "            # Also flip y coordinates, so that they're correctly read into x array\n",
    "            # y_grid_flip = np.flip(y_grid)\n",
    "            # NOTE: adding 0.25 to y coord so that it marks Top left corner\n",
    "            # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "            y_grid_flip = np.flip(y_grid) + xysize\n",
    "            \n",
    "            # put in an xarray\n",
    "            # 2D\n",
    "            m_xr = xr.DataArray(data=m,\n",
    "                                coords={\"y\": y_grid_flip,\n",
    "                                        \"x\": x_grid},\n",
    "                                dims=[\"y\", \"x\"])\n",
    "\n",
    "            # Write CRS and Nodata value and dims to xarray\n",
    "            m_xr.rio.write_crs(f\"epsg:{epsg}\",\n",
    "                               inplace=True)\n",
    "            m_xr.rio.write_nodata(-9999,\n",
    "                                  inplace=True)\n",
    "            m_xr.rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                      y_dim=\"y\",\n",
    "                                      inplace=True)\n",
    "            m_xr.rio.write_coordinate_system(inplace=True)\n",
    "            \n",
    "            # make an output Label\n",
    "            label = l.replace(' ', '').replace('.', 'p').replace('[m]', '')\n",
    "\n",
    "            m_xr.rio.to_raster(f'{outdir_rast}/{s}/2D/UHURU{s}{str(b)}_{label}.tif')\n",
    "            \n",
    "            print(f'{l} done')\n",
    "    \n",
    "        end2d = time.time()\n",
    "        \n",
    "        print(f'Finished 2D outputs for UHURU {s} Block {b}. {end2d-start} seconds. \\n')\n",
    "\n",
    "    \n",
    "    # 3) Load, Reshape, and Output 3D Metrics\n",
    "\n",
    "        # Unpack cover values as a list\n",
    "        v3 = list(cover.values())\n",
    "\n",
    "        # Get list of heights for later\n",
    "        hbins = v3[0]['HeightBins']\n",
    "        \n",
    "        shape = (len(x_grid), len(y_grid))\n",
    "\n",
    "        # for each set of 3D metrics\n",
    "        for l3 in metriclabels3d:\n",
    "\n",
    "            # list to fill with xarrays from each height\n",
    "            xr_list = []\n",
    "            \n",
    "            # Deals with an issue caused by using np.diff\n",
    "            # if there's a difference metric, then the last height does not have a value\n",
    "            if ((\"byH\" in l3) | ('FHP' in l3)) :\n",
    "                hbinz = hbins[0:-1]\n",
    "            else:\n",
    "                hbinz = hbins\n",
    "            \n",
    "            # for each height bin\n",
    "            for hidx, h in enumerate(hbinz): \n",
    "\n",
    "                # make an array of all the values\n",
    "                m = np.array([i[l3][hidx] for i in v3])\n",
    "\n",
    "                # make an empty output array, filled with nans\n",
    "                output_array = np.full(shape, np.nan)\n",
    "\n",
    "                # if that data needs to be filtered\n",
    "                if filterindex:\n",
    "\n",
    "                    data = m[filterindex]\n",
    "                    xindices = np.array(xidx)[filterindex]\n",
    "                    yindices = np.array(yidx)[filterindex]\n",
    "            \n",
    "                # Convert to int\n",
    "                xindices = np.array(xindices).astype(int)\n",
    "                yindices = np.array(yindices).astype(int)\n",
    "                \n",
    "                # Fill any inf values in data with -9999\n",
    "                # data[np.isfinite(data, where=False)] = -9999\n",
    "\n",
    "                # stick into the array\n",
    "                # IMPORTANT NOTE HERE: it's y, then x, not the other way around\n",
    "                output_array[yindices, xindices] = data\n",
    "                \n",
    "                # Mirror Image the metric\n",
    "                # Note: You do this because rioxarray wants data\n",
    "                # ordered with positive x (left to right)\n",
    "                # but with negative y (top to bottom)\n",
    "                # This really just makes the export to geotif go smoothly,\n",
    "                # with a correct affine transform \n",
    "                output_array = np.flipud(output_array)\n",
    "\n",
    "                # Also flip y coordinates, so that they're correctly read into x array \n",
    "                # y_grid_flip = np.flip(y_grid)\n",
    "                # NOTE: adding xysize to y coord so that it marks Top left corner\n",
    "                # instead of bottom left - this is in accordance with raster data and rioxarray\n",
    "                y_grid_flip = np.flip(y_grid) + xysize\n",
    "\n",
    "                # put in an xarray\n",
    "                # 2D\n",
    "                m_xr = xr.DataArray(data=output_array,\n",
    "                                    coords={\"y\": y_grid_flip,\n",
    "                                            \"x\": x_grid},\n",
    "                                    dims=[\"y\", \"x\"])\n",
    "\n",
    "                # Write CRS and Nodata value\n",
    "                m_xr.rio.write_crs(f\"epsg:{epsg}\", inplace=True)\n",
    "                m_xr.rio.write_nodata(-9999, inplace=True)\n",
    "                m_xr.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n",
    "                m_xr.rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "                # add to list \n",
    "                xr_list.append(m_xr)\n",
    "\n",
    "            # Concatenate dataarrays\n",
    "            # https://docs.xarray.dev/en/stable/user-guide/combining.html#combine\n",
    "            # setting the values of the new dimension to be height\n",
    "            ds = xr.concat(xr_list, hbinz)\n",
    "            ds = ds.rename({'concat_dim':'z'})\n",
    "\n",
    "            # Set it's name\n",
    "            ds.name = l3\n",
    "\n",
    "            # output to netcdf\n",
    "            ds.to_netcdf(f'{outdir_rast}/{s}/3D/UHURU{s}{str(b)}_{l3}.nc')\n",
    "\n",
    "        end3d = time.time()\n",
    "\n",
    "        print(f'Finished 3D outputs for UHURU {s} Block {b}. {end3d-end2d} seconds. \\n')\n",
    "\n",
    "    # DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeab52b-326c-4140-9048-c907397da388",
   "metadata": {},
   "source": [
    "complexity.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Halo]",
   "language": "python",
   "name": "conda-env-.conda-Halo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
